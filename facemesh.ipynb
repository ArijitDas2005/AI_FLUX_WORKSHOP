{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cam = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow('Eye Controlled Mouse', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 import facemesh\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "cam = cv2.VideoCapture(0)\n",
    "#call the facemesh library\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh()\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    ###########\n",
    "    output = face_mesh.process(rgb_frame)#process the facemesh-detects and gives the facial landmarks\n",
    "    landmark_points = output.multi_face_landmarks#stores the landmarks\n",
    "    print(landmark_points)\n",
    "    ############\n",
    "    cv2.imshow('Eye Controlled Mouse', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh()\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    if landmark_points:#####3 get x and y coordinates\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for landmark in landmarks:\n",
    "            x=landmark.x\n",
    "            y=landmark.y\n",
    "            print(x,y)\n",
    "            ########\n",
    "    cv2.imshow('Eye Controlled Mouse', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Get frame width and height\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh()\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape#######\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for landmark in landmarks:\n",
    "            x = int(landmark.x * frame_w)#####\n",
    "            y = int(landmark.y * frame_h)######\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))#########\n",
    "            ###########\n",
    "    cv2.imshow('Eye Controlled Mouse', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)##gives 478 landmarks\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for landmark in landmarks[474:478]:\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            \n",
    "    cv2.imshow('Eye Controlled Mouse', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for landmark in landmarks[474:478]:#select a range of land marks\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            \n",
    "    cv2.imshow('Eye Controlled Mouse', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui #import pyautogui\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for id, landmark in enumerate(landmarks[474:478]):#enumrate the points\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            if id == 1:# move the cursor based on the x,y value\n",
    "               pyautogui.moveTo(x, y)\n",
    "            \n",
    "    cv2.imshow('Eye Controlled Mouse', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui #import pyautogui\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)\n",
    "screen_w, screen_h = pyautogui.size() #get height and width of the monitor\n",
    "\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for id, landmark in enumerate(landmarks[474:478]):\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            if id == 1:\n",
    "                screen_x = screen_w / frame_w * x #apply to match to screen\n",
    "                screen_y = screen_h / frame_h *y\n",
    "                pyautogui.moveTo(screen_x, screen_y)\n",
    "            \n",
    "    cv2.imshow('Eye Controlled Mouse', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui #import pyautogui\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)\n",
    "screen_w, screen_h = pyautogui.size() \n",
    "\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for id, landmark in enumerate(landmarks[474:478]):\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            if id == 1:\n",
    "                screen_x = screen_w / frame_w * x \n",
    "                screen_y = screen_h / frame_h *y\n",
    "                pyautogui.moveTo(screen_x, screen_y)\n",
    "        left = [landmarks[145], landmarks[159]] #set up left eye for clicking\n",
    "        for landmark in left:\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 255))  \n",
    "    cv2.imshow('Eye Controlled Mouse', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui #import pyautogui\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)\n",
    "screen_w, screen_h = pyautogui.size() \n",
    "\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for id, landmark in enumerate(landmarks[474:478]):\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            if id == 1:\n",
    "                screen_x = screen_w / frame_w * x \n",
    "                screen_y = screen_h / frame_h *y\n",
    "                pyautogui.moveTo(screen_x, screen_y)\n",
    "        left = [landmarks[145], landmarks[159]]\n",
    "        for landmark in left:\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 255)) \n",
    "        print(left[0].y,left[1].y)#get left eye vertical coordinates\n",
    "    cv2.imshow('Eye Controlled Mouse', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui #import pyautogui\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)\n",
    "screen_w, screen_h = pyautogui.size() \n",
    "\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for id, landmark in enumerate(landmarks[474:478]):\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            if id == 1:\n",
    "                screen_x = screen_w / frame_w * x \n",
    "                screen_y = screen_h / frame_h *y\n",
    "                pyautogui.moveTo(screen_x, screen_y)\n",
    "        left = [landmarks[145], landmarks[159]]\n",
    "        for landmark in left:\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 255)) \n",
    "        print(left[0].y-left[1].y)#find difference when eye open and eye close\n",
    "    cv2.imshow('Eye Controlled Mouse', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui #import pyautogui\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)\n",
    "screen_w, screen_h = pyautogui.size() \n",
    "\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for id, landmark in enumerate(landmarks[474:478]):\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            if id == 1:\n",
    "                screen_x = screen_w / frame_w * x \n",
    "                screen_y = screen_h / frame_h *y\n",
    "                pyautogui.moveTo(screen_x, screen_y)\n",
    "        left = [landmarks[145], landmarks[159]]\n",
    "        for landmark in left:\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 255)) \n",
    "        if (left[0].y - left[1].y) < 0.005:\n",
    "            print(\"click\")\n",
    "    cv2.imshow('Eye Controlled Mouse', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui #import pyautogui\n",
    "cam = cv2.VideoCapture(0)\n",
    "face_mesh = mp.solutions.face_mesh.FaceMesh(refine_landmarks=True)\n",
    "screen_w, screen_h = pyautogui.size() \n",
    "\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = face_mesh.process(rgb_frame)\n",
    "    landmark_points = output.multi_face_landmarks\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if landmark_points:\n",
    "        landmarks = landmark_points[0].landmark\n",
    "        for id, landmark in enumerate(landmarks[474:478]):\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 0))\n",
    "            if id == 1:\n",
    "                screen_x = screen_w / frame_w * x \n",
    "                screen_y = screen_h / frame_h *y\n",
    "                pyautogui.moveTo(screen_x, screen_y)\n",
    "        left = [landmarks[145], landmarks[159]]\n",
    "        for landmark in left:\n",
    "            x = int(landmark.x * frame_w)\n",
    "            y = int(landmark.y * frame_h)\n",
    "            cv2.circle(frame, (x, y), 3, (0, 255, 255)) \n",
    "        if (left[0].y - left[1].y) < 0.005:\n",
    "            pyautogui.click()\n",
    "            pyautogui.sleep(1)\n",
    "    cv2.imshow('Eye Controlled Mouse', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
